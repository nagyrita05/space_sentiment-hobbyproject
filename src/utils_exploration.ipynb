{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecbfb28d-a68c-42ca-8cd4-ca3f43a4701e",
   "metadata": {},
   "source": [
    "## A `utils.py` szerepe:\n",
    "\n",
    "A `utils.py` a közös, ismétlődő kódokat tartalmazza:\n",
    "\n",
    "- országlisták: `countries` (angol), `non_english_countries` (nem angol),\n",
    "  és az `iso2_to_iso3` kódmapping (a térképekhez kell az ISO3);\n",
    "- letöltés: `fetch_gnews_for_countries(topic_query, country_list, ...)`;\n",
    "- érzelemelemzés:\n",
    "  - EN: `score_sentiment_vader` (VADER modellel),\n",
    "  - NON-EN: `load_xlmr_model` + `predict_sentiment_batch_xlmr` (XLM-R);\n",
    "- kényelmi helperek: `add_iso3(df)` és `get_countries_df()`;\n",
    "- aggregálás + 4 térkép egy hívással: `plot_four_maps_for_topic(all_news, topic_name)`;\n",
    "- példacímek listázása: `top_examples_all(all_news, label=\"positive\"/\"negative\")`.\n",
    "\n",
    "Előny: a 4 altéma notebookja egységes, rövid, jól olvasható. Újrafuttatáskor csak a \n",
    "`TOPIC_NAME` és a `topic_query` változik.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbdd6970-a3a1-47f9-b503-5f3b0fc8978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py\n",
    "\n",
    "# Közös segédfüggvények + országlisták + ISO mapping\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Országlisták és ISO kód mapping ----------\n",
    "\n",
    "# Angol nyelvű országok: (country_name, iso2, hl, gl, ceid)\n",
    "countries = [\n",
    "    (\"United States\",\"US\",\"en-US\",\"US\",\"US:en\"),\n",
    "    (\"United Kingdom\",\"GB\",\"en-GB\",\"GB\",\"GB:en\"),\n",
    "    (\"Canada\",\"CA\",\"en-CA\",\"CA\",\"CA:en\"),\n",
    "    (\"Australia\",\"AU\",\"en-AU\",\"AU\",\"AU:en\"),\n",
    "    (\"India\",\"IN\",\"en-IN\",\"IN\",\"IN:en\"),\n",
    "    (\"Ireland\",\"IE\",\"en-IE\",\"IE\",\"IE:en\"),\n",
    "    (\"South Africa\",\"ZA\",\"en-ZA\",\"ZA\",\"ZA:en\"),\n",
    "    (\"Singapore\",\"SG\",\"en-SG\",\"SG\",\"SG:en\"),\n",
    "    (\"New Zealand\",\"NZ\",\"en-NZ\",\"NZ\",\"NZ:en\"),\n",
    "    (\"Philippines\",\"PH\",\"en-PH\",\"PH\",\"PH:en\"),\n",
    "    (\"Nigeria\",\"NG\",\"en-NG\",\"NG\",\"NG:en\"),\n",
    "    (\"Kenya\",\"KE\",\"en-KE\",\"KE\",\"KE:en\"),\n",
    "    (\"Hong Kong\",\"HK\",\"en-HK\",\"HK\",\"HK:en\"),\n",
    "    (\"Malaysia\",\"MY\",\"en-MY\",\"MY\",\"MY:en\"),\n",
    "    (\"United Arab Emirates\",\"AE\",\"en-AE\",\"AE\",\"AE:en\"),\n",
    "    (\"Pakistan\",\"PK\",\"en-PK\",\"PK\",\"PK:en\"),\n",
    "    (\"Bangladesh\",\"BD\",\"en-BD\",\"BD\",\"BD:en\"),\n",
    "    (\"Ghana\",\"GH\",\"en-GH\",\"GH\",\"GH:en\"),\n",
    "    (\"Tanzania\",\"TZ\",\"en-TZ\",\"TZ\",\"TZ:en\"),\n",
    "    (\"Uganda\",\"UG\",\"en-UG\",\"UG\",\"UG:en\"),\n",
    "    (\"Jamaica\",\"JM\",\"en-JM\",\"JM\",\"JM:en\"),\n",
    "]\n",
    "\n",
    "# Nem angol országok (példák az altémához): (country_name, iso2, hl, gl, ceid)\n",
    "non_english_countries = [\n",
    "    (\"China\",  \"CN\", \"zh-CN\", \"CN\", \"CN:zh-Hans\"),\n",
    "    (\"Russia\", \"RU\", \"ru-RU\", \"RU\", \"RU:ru\"),\n",
    "    (\"Germany\",\"DE\", \"de-DE\", \"DE\", \"DE:de\"),\n",
    "    (\"France\", \"FR\", \"fr-FR\", \"FR\", \"FR:fr\"),\n",
    "    (\"Spain\",  \"ES\", \"es-ES\", \"ES\", \"ES:es\"),\n",
    "]\n",
    "\n",
    "# ISO2 -> ISO3\n",
    "iso2_to_iso3 = {\n",
    "    \"US\":\"USA\",\"GB\":\"GBR\",\"CA\":\"CAN\",\"AU\":\"AUS\",\"IN\":\"IND\",\"IE\":\"IRL\",\"ZA\":\"ZAF\",\n",
    "    \"SG\":\"SGP\",\"NZ\":\"NZL\",\"PH\":\"PHL\",\"NG\":\"NGA\",\"KE\":\"KEN\",\"HK\":\"HKG\",\n",
    "    \"MY\":\"MYS\",\"AE\":\"ARE\",\"PK\":\"PAK\",\"BD\":\"BGD\",\"GH\":\"GHA\",\"TZ\":\"TZA\",\"UG\":\"UGA\",\"JM\":\"JAM\",\n",
    "    \"CN\":\"CHN\",\"RU\":\"RUS\",\"DE\":\"DEU\",\"FR\":\"FRA\",\"ES\":\"ESP\"\n",
    "}\n",
    "\n",
    "# ---------- Kényelmi helperek: országlista DF és ISO3 hozzáadás ----------\n",
    "\n",
    "def get_countries_df():\n",
    "    \"\"\"Országlista DataFrame-ként + iso3 oszlop.\"\"\"\n",
    "    cols = [\"country_name\",\"iso2\",\"hl\",\"gl\",\"ceid\"]\n",
    "    df = pd.DataFrame(countries, columns=cols)\n",
    "    df[\"iso3\"] = df[\"iso2\"].map(iso2_to_iso3)\n",
    "    return df\n",
    "\n",
    "def add_iso3(df: pd.DataFrame, iso2_col=\"iso2\"):\n",
    "    \"\"\"Hozzáadja/kitölti az iso3 oszlopot a megadott iso2 oszlop alapján.\"\"\"\n",
    "    out = df.copy()\n",
    "    out[\"iso3\"] = out[iso2_col].map(iso2_to_iso3)\n",
    "    return out\n",
    "\n",
    "# ---------- RSS letöltés Google Newsból ----------\n",
    "\n",
    "def fetch_gnews_for_country(topic_query: str, hl: str, gl: str, ceid: str, limit=120):\n",
    "    \"\"\"Egy ország (hl/gl/ceid) RSS-e egy queryre. Vissza: DataFrame(title, link, published, source).\"\"\"\n",
    "    import feedparser\n",
    "    from urllib.parse import quote_plus\n",
    "    url = f\"https://news.google.com/rss/search?q={quote_plus(topic_query)}&hl={hl}&gl={gl}&ceid={ceid}\"\n",
    "    feed = feedparser.parse(url)\n",
    "    rows = []\n",
    "    for e in feed.entries[:limit]:\n",
    "        rows.append({\n",
    "            \"title\": e.get(\"title\",\"\"),\n",
    "            \"link\": e.get(\"link\",\"\"),\n",
    "            \"published\": e.get(\"published\",\"\"),\n",
    "            \"source\": (getattr(e, \"source\", {}).get(\"title\")\n",
    "                       if hasattr(e, \"source\") and isinstance(getattr(e,\"source\"), dict)\n",
    "                       else \"\")\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def fetch_gnews_for_countries(topic_query: str, country_list, limit=120, source_lang=\"EN\"):\n",
    "    \"\"\"\n",
    "    Több ország lekérése és összefűzése.\n",
    "    country_list: list of tuples (country_name, iso2, hl, gl, ceid)\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for name, iso2, hl, gl, ceid in country_list:\n",
    "        df = fetch_gnews_for_country(topic_query, hl, gl, ceid, limit=limit)\n",
    "        df[\"country\"] = name\n",
    "        df[\"iso2\"] = iso2\n",
    "        df[\"source_lang\"] = source_lang\n",
    "        frames.append(df)\n",
    "    out = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "    if not out.empty:\n",
    "        out = out.drop_duplicates(subset=[\"title\",\"link\"]).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "# ---------- VADER az angol headline-okra ----------\n",
    "\n",
    "def score_sentiment_vader(text: str):\n",
    "    \"\"\"VADER compound score (-1..+1). Notebookban töltsd le a lexicont.\"\"\"\n",
    "    if not isinstance(text, str): \n",
    "        return 0.0\n",
    "    try:\n",
    "        from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        return sia.polarity_scores(text)[\"compound\"]\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "# ---------- Többnyelvű (XLM-R) modell a nem angol címekhez ----------\n",
    "\n",
    "def load_xlmr_model(model_name=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"):\n",
    "    \"\"\"\n",
    "    Betölti a tokenizer+modellt. Lassabb, mert use_fast=False (nincs tokenizers build).\n",
    "    CUDA ha elérhető.\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tok = XLMRobertaTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "    mdl = XLMRobertaForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "    mdl.eval()\n",
    "    return tok, mdl, device\n",
    "\n",
    "def predict_sentiment_batch_xlmr(texts, tok, mdl, device, batch_size=24, max_length=128):\n",
    "    \"\"\"Címkék: negative / neutral / positive. Vissza: lista címkékkel.\"\"\"\n",
    "    import torch\n",
    "    labels = [\"negative\",\"neutral\",\"positive\"]\n",
    "    preds = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = [t if isinstance(t,str) and t.strip() else \"\" for t in texts[i:i+batch_size]]\n",
    "        enc = tok(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length)\n",
    "        enc = {k:v.to(device) for k,v in enc.items()}\n",
    "        with torch.no_grad():\n",
    "            logits = mdl(**enc).logits\n",
    "            idx = torch.softmax(logits, dim=1).argmax(dim=1).cpu().numpy()\n",
    "        preds.extend([labels[j] for j in idx])\n",
    "    return preds\n",
    "\n",
    "# ---------- Ország-szintű aggregálások + 4 térkép + CSV ----------\n",
    "\n",
    "def make_country_aggregates(all_news: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Elvárás: all_news tartalmazza a 'country', 'sentiment' (számszerű), 'sentiment_label' oszlopokat.\n",
    "    Vissza: dict {median, mean, pos_ratio, neg_ratio} DataFrame-ekkel.\n",
    "    \"\"\"\n",
    "    med = (all_news.groupby(\"country\", as_index=False)[\"sentiment\"]\n",
    "           .median().rename(columns={\"sentiment\":\"median_sentiment\"}))\n",
    "    mean = (all_news.groupby(\"country\", as_index=False)[\"sentiment\"]\n",
    "            .mean().rename(columns={\"sentiment\":\"mean_sentiment\"}))\n",
    "    pos = (all_news.groupby(\"country\")[\"sentiment_label\"]\n",
    "           .apply(lambda s: (s==\"positive\").mean())\n",
    "           .reset_index().rename(columns={\"sentiment_label\":\"positive_ratio\"}))\n",
    "    neg = (all_news.groupby(\"country\")[\"sentiment_label\"]\n",
    "           .apply(lambda s: (s==\"negative\").mean())\n",
    "           .reset_index().rename(columns={\"sentiment_label\":\"negative_ratio\"}))\n",
    "    return {\"median\": med, \"mean\": mean, \"pos_ratio\": pos, \"neg_ratio\": neg}\n",
    "\n",
    "def _maybe_add_iso3(df, all_news):\n",
    "    if \"iso3\" in all_news.columns:\n",
    "        return df.merge(all_news[[\"country\",\"iso3\"]].drop_duplicates(), on=\"country\", how=\"left\")\n",
    "    return df\n",
    "\n",
    "def plot_four_maps_for_topic(all_news: pd.DataFrame, topic_name: str, use_iso3=True):\n",
    "    \"\"\"\n",
    "    Négy plotly choropleth: medián, átlag, pozitív és negatív arány (EN+NON_EN összevonva).\n",
    "    A CSV-ket az outputs/<topic>/csv mappába menti.\n",
    "    \"\"\"\n",
    "    import plotly.express as px\n",
    "    os.makedirs(f\"outputs/{topic_name}/csv\", exist_ok=True)\n",
    "\n",
    "    aggs = make_country_aggregates(all_news)\n",
    "    med = _maybe_add_iso3(aggs[\"median\"], all_news)\n",
    "    avg = _maybe_add_iso3(aggs[\"mean\"], all_news)\n",
    "    pos = _maybe_add_iso3(aggs[\"pos_ratio\"], all_news)\n",
    "    neg = _maybe_add_iso3(aggs[\"neg_ratio\"], all_news)\n",
    "\n",
    "    def _plot(df, value_col, title):\n",
    "        if use_iso3 and \"iso3\" in df.columns:\n",
    "            fig = px.choropleth(df, locations=\"iso3\", color=value_col,\n",
    "                                hover_name=\"country\",\n",
    "                                color_continuous_scale=\"RdYlGn\",\n",
    "                                range_color=(df[value_col].min(), df[value_col].max()),\n",
    "                                title=title)\n",
    "        else:\n",
    "            fig = px.choropleth(df, locations=\"country\", locationmode=\"country names\",\n",
    "                                color=value_col,\n",
    "                                color_continuous_scale=\"RdYlGn\",\n",
    "                                range_color=(df[value_col].min(), df[value_col].max()),\n",
    "                                title=title)\n",
    "        fig.show()\n",
    "\n",
    "    _plot(med, \"median_sentiment\", f\"{topic_name} – Median sentiment (EN + NON_EN)\")\n",
    "    _plot(avg, \"mean_sentiment\",   f\"{topic_name} – Mean sentiment (EN + NON_EN)\")\n",
    "    _plot(pos, \"positive_ratio\",   f\"{topic_name} – Positive share (EN + NON_EN)\")\n",
    "    _plot(neg, \"negative_ratio\",   f\"{topic_name} – Negative share (EN + NON_EN)\")\n",
    "\n",
    "    safe = topic_name\n",
    "    med.to_csv(f\"outputs/{safe}/csv/{safe}_median_by_country.csv\", index=False)\n",
    "    avg.to_csv(f\"outputs/{safe}/csv/{safe}_mean_by_country.csv\", index=False)\n",
    "    pos.to_csv(f\"outputs/{safe}/csv/{safe}_positive_ratio_by_country.csv\", index=False)\n",
    "    neg.to_csv(f\"outputs/{safe}/csv/{safe}_negative_ratio_by_country.csv\", index=False)\n",
    "\n",
    "# ---------- TOP példacímek ----------\n",
    "\n",
    "def top_examples_all(all_news, label=\"positive\", k=10, per_country=False):\n",
    "    df = all_news[all_news[\"sentiment_label\"].eq(label)].copy()\n",
    "    if \"sentiment\" in df.columns:\n",
    "        df = df.sort_values(\"sentiment\", ascending=(label==\"negative\"))\n",
    "    keep = [c for c in [\"country\",\"source_lang\",\"title\",\"sentiment\",\"sentiment_label\",\"source\",\"link\"] if c in df.columns]\n",
    "    df = df[keep]\n",
    "    if per_country:\n",
    "        return df.groupby(\"country\", group_keys=False).head(k).reset_index(drop=True)\n",
    "    return df.head(k).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791a876-75da-424d-b446-1d4795db3a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
